R1: Os dois problemas desta "solução" para o problema dos buffers limitados, são o 'mutex = 2' e P(mutex), V(mutex) não estão restringindo apenas as áreas de recursos compartilhados.
A seguinte explicação se aplica tanto a Thread Producer quanto a Thread Consumer. 
O primeiro problema, mutex = 2, implica que duas threads poderão passar pelo P(mutex), já que P(mutex) trava quando o mutex for igual a zero. Assim, a primeira thread passa por P(mutex), decrementa mutex em uma unidade, assim mutex = 1. Outra thread passa por P(mutex), e decrementa o mutex novamente em uma unidade, agora mutex = 0. Assim, as duas threads passaram por P(mutex) e todas as outras estão esperando elas passarem pela seção crítica.
Após isto, em Thread Producer, as duas threads irão pedir acesso ao P(empty). E as duas conseguirão passar por P(empty), pois como empty = n e n > 1, quando a primeira thread passar, decrementará o empty em uma unidade, empty = n-1 != 0, e a segunda thread passará e também irá decrementar empty em uma unidade, empty = n-2 >= 0.
Assim, as duas threads irão acessar a parte de recurso compartilhado (buf[rear] = data; rear = (rear + 1) % n;) e como esses dois comandos não são atômicos, a primeira thread pode armazenar na posição rear o 'data' e logo depois o sistema operacional chaveia para a próxima thread que armazena também na posição rear o 'data', porque não deu tempo da primeira thread executar o passo seguinte. Após isso, independente da ordem, as threads irão atualizar rear em uma unidade. E depois irão passar por V(full) que incrementará duas unidades em full e passa a informação ao Consumer que há duas mensagens a serem lidas, no entanto só há uma informação sobrescrita no vetor buf.
Depois disso, as threads acessam o V(mutex), a primeira incrementa mutex em uma unidade, e a segunda thread também incrementa em uma unidade o mutex. Liberando as threads seguintes a acessarem a região crítica.
O mesmo raciocínio se aplica à Thread Consumer, mas irei esmiuçar da mesma forma. 
Após a passagem das threads pelo P(mutex), descrito anteriormente e que vale para a seguinte explicação, as duas threads irão pedir acesso ao P(full). E as duas conseguirão passar por P(full), pois como full = 2, como descrito antes, quando a primeira thread passar, decrementará o full em uma unidade, full = 1, e a segunda thread passará e também irá decrementar full em uma unidade, full = 0.
Assim, as duas threads irão acessar a parte de recurso compartilhado (result = buf[front]; front = (front + 1) % n;) e como esses dois comandos não são atômicos, a primeira thread pode armazenar na variável local 'result' a mensagem em buf[front] e logo depois o sistema operacional chaveia para a próxima thread que armazena também na variável local 'result' a mesma mensagem de buf[front], porque não deu tempo da primeira thread executar o passo seguinte. Após isso, independente da ordem, as threads irão atualizar o front em uma unidade. E depois irão passar por V(empty) que incrementará duas unidades, passando a informação ao Producer que duas mensagens foram lidas, no entanto só uma informação foi lida duas vezes do vetor buf.
Depois disso, as threads acessam o V(mutex), a primeira incrementa mutex em uma unidade, e a segunda thread também incrementa em uma unidade o mutex. Liberando as threads seguintes a acessarem a região crítica.
O segundo problema apresentado na implementação é que P(mutex) e V(mutex) restringem uma parte maior do que a área de recursos compartilhados, travando as outras partes, resultando em uma execução mais lenta, o que é ineficiente. Esmiuçando essa explicação, se as threads usam bastante cpu e a máquina possui mais de um processador, o programa não estará usando os vários processadores da máquina, ele estará usando como se tivesse apenas uma unidade de processamento. Disto retiramos a ineficiência que gera essa implementação.

R2: Acredito que cada um contribuiu 50% ao ep1.
